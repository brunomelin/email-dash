# üöÄ Solu√ß√£o: Cache a N√≠vel de Servidor

**Data:** 13 de Janeiro de 2026  
**Status:** ‚≠ê **RECOMENDADO**

---

## üéØ **Vis√£o Geral**

Implementar cache a n√≠vel de servidor para cachear:
1. **Resultado de `/automations/{id}/campaigns`** (87 automa√ß√µes)
2. **Resultado de API v1 por per√≠odo** (m√©tricas de data)
3. **Queries de automa√ß√µes do banco**

**Benef√≠cios:**
- ‚úÖ **Cache compartilhado** entre todos os usu√°rios
- ‚úÖ **Persiste entre requests**
- ‚úÖ **TTL configur√°vel** (ex: 5 minutos)
- ‚úÖ **Reduz 90%+ das chamadas √† API**

---

## üìä **Compara√ß√£o de Performance**

### **SEM Cache (Atual):**
```
Usu√°rio 1: 347 HTTP requests ‚Üí 40 segundos
Usu√°rio 2: 347 HTTP requests ‚Üí 40 segundos  
Usu√°rio 3: 347 HTTP requests ‚Üí 40 segundos
Total: 1041 requests em 2 minutos
```

### **COM Cache:**
```
Usu√°rio 1: 347 requests ‚Üí 40s (preenche cache)
Usu√°rio 2: 0 requests ‚Üí 2s (cache hit!)
Usu√°rio 3: 0 requests ‚Üí 2s (cache hit!)
Ap√≥s 5min: 347 requests ‚Üí 40s (renova cache)
Total: 347 requests em 2 minutos
```

**Redu√ß√£o:** 70% menos requests, 95% mais r√°pido para usu√°rios subsequentes!

---

## üîß **3 Op√ß√µes de Implementa√ß√£o**

### **Op√ß√£o 1: Next.js `unstable_cache`** ‚≠ê **RECOMENDADO**

**Descri√ß√£o:** Cache nativo do Next.js 14/15

**Vantagens:**
- ‚úÖ Built-in (zero depend√™ncias)
- ‚úÖ Funciona em Vercel, Railway, etc
- ‚úÖ API simples
- ‚úÖ Cache entre requests
- ‚úÖ TTL autom√°tico

**C√≥digo:**

```typescript
// src/lib/cache/server-cache.ts
import { unstable_cache } from 'next/cache'

/**
 * Cache para chamadas de API do ActiveCampaign
 * TTL: 5 minutos
 */
export const getCachedAutomationCampaigns = unstable_cache(
  async (automationId: string, baseUrl: string, apiKey: string) => {
    const client = new ActiveCampaignClient({ baseUrl, apiKey })
    return await client.getAutomationCampaigns(automationId)
  },
  ['automation-campaigns'], // cache key prefix
  {
    revalidate: 300, // 5 minutos
    tags: ['automation-campaigns']
  }
)

/**
 * Cache para m√©tricas de campanha (API v1)
 */
export const getCachedCampaignMetrics = unstable_cache(
  async (
    campaignId: string,
    sdate: string,
    ldate: string,
    baseUrl: string,
    apiKey: string
  ) => {
    const apiv1 = new ActiveCampaignAPIv1({ baseUrl, apiKey })
    return await apiv1.getCampaignReportTotals(campaignId, { sdate, ldate })
  },
  ['campaign-metrics'],
  {
    revalidate: 300,
    tags: ['campaign-metrics']
  }
)

/**
 * Cache para lista de automa√ß√µes
 */
export const getCachedAutomations = unstable_cache(
  async (accountIds: string[]) => {
    return await prisma.automation.findMany({
      where: { accountId: { in: accountIds } },
      include: {
        account: {
          select: { name: true, baseUrl: true, apiKey: true }
        }
      },
      orderBy: { name: 'asc' }
    })
  },
  ['automations-list'],
  {
    revalidate: 300,
    tags: ['automations']
  }
)
```

**Uso no Service:**

```typescript
// src/lib/services/automation-metrics-service.ts
import { getCachedAutomationCampaigns, getCachedCampaignMetrics } from '@/lib/cache/server-cache'

async getAutomationsWithMetricsV2(filters: AutomationFilters = {}) {
  // 1. Buscar automa√ß√µes (CACHADO)
  const automations = await getCachedAutomations(filters.accountIds || [])
  
  // 2. Para cada automa√ß√£o, buscar campanhas (CACHADO)
  const automationsWithCampaigns = await Promise.all(
    automations.map(async (automation) => {
      try {
        // ‚úÖ Cache hit = instant√¢neo!
        const apiCampaigns = await getCachedAutomationCampaigns(
          automation.id,
          automation.account.baseUrl,
          automation.account.apiKey
        )
        
        // Buscar do banco (pode adicionar cache tamb√©m)
        const campaigns = await prisma.campaign.findMany(...)
        
        return { automation, campaigns }
      } catch (error) {
        // Fallback...
      }
    })
  )
  
  // 3. Se filtro de data, buscar m√©tricas (CACHADO)
  if (filters.dateFrom || filters.dateTo) {
    for (const item of automationsWithCampaigns) {
      item.campaigns = await Promise.all(
        item.campaigns.map(async (campaign) => {
          // ‚úÖ Cache hit = instant√¢neo!
          const metrics = await getCachedCampaignMetrics(
            campaign.id,
            sdate,
            ldate,
            item.automation.account.baseUrl,
            item.automation.account.apiKey
          )
          
          return { ...campaign, ...metrics }
        })
      )
    }
  }
  
  // Resto do c√≥digo...
}
```

**Invalida√ß√£o de Cache:**

```typescript
// Ap√≥s sincroniza√ß√£o, invalidar cache
import { revalidateTag } from 'next/cache'

// src/app/actions/sync.ts
export async function syncAccountAction(accountId: string) {
  await syncService.syncAccount(accountId)
  
  // Invalidar caches relacionados
  revalidateTag('automations')
  revalidateTag('automation-campaigns')
  revalidateTag('campaign-metrics')
  
  return { success: true }
}
```

**Resultado:**
- **Primeira carga:** 30-40s (preenche cache)
- **Cargas subsequentes:** 2-5s (cache hit)
- **Ap√≥s 5 minutos:** Cache expira, renova automaticamente

---

### **Op√ß√£o 2: Cache em Mem√≥ria (Map)** üîÑ

**Descri√ß√£o:** Cache simples usando `Map` do JavaScript

**Vantagens:**
- ‚úÖ Muito simples
- ‚úÖ Zero depend√™ncias
- ‚úÖ Controle total

**Desvantagens:**
- ‚ö†Ô∏è Perde ao reiniciar servidor
- ‚ö†Ô∏è N√£o funciona em serverless (Vercel)
- ‚ö†Ô∏è N√£o compartilha entre inst√¢ncias

**C√≥digo:**

```typescript
// src/lib/cache/memory-cache.ts
interface CacheEntry<T> {
  data: T
  timestamp: number
  ttl: number
}

class MemoryCache {
  private cache = new Map<string, CacheEntry<any>>()
  
  set<T>(key: string, data: T, ttlSeconds: number = 300) {
    this.cache.set(key, {
      data,
      timestamp: Date.now(),
      ttl: ttlSeconds * 1000
    })
  }
  
  get<T>(key: string): T | null {
    const entry = this.cache.get(key)
    
    if (!entry) return null
    
    // Verificar TTL
    if (Date.now() - entry.timestamp > entry.ttl) {
      this.cache.delete(key)
      return null
    }
    
    return entry.data as T
  }
  
  clear(prefix?: string) {
    if (!prefix) {
      this.cache.clear()
      return
    }
    
    // Limpar por prefixo
    for (const key of this.cache.keys()) {
      if (key.startsWith(prefix)) {
        this.cache.delete(key)
      }
    }
  }
  
  // Limpar cache expirado periodicamente
  startCleanup(intervalMs: number = 60000) {
    setInterval(() => {
      const now = Date.now()
      for (const [key, entry] of this.cache.entries()) {
        if (now - entry.timestamp > entry.ttl) {
          this.cache.delete(key)
        }
      }
    }, intervalMs)
  }
}

export const serverCache = new MemoryCache()

// Iniciar cleanup ao iniciar servidor
serverCache.startCleanup()
```

**Uso:**

```typescript
// Wrapper com cache
async function getAutomationCampaignsWithCache(
  automationId: string,
  client: ActiveCampaignClient
) {
  const cacheKey = `automation:${automationId}:campaigns`
  
  // Tentar do cache
  const cached = serverCache.get<any[]>(cacheKey)
  if (cached) {
    console.log(`‚úÖ Cache hit: ${cacheKey}`)
    return cached
  }
  
  // Buscar da API
  console.log(`üì° Cache miss: ${cacheKey}, buscando da API...`)
  const data = await client.getAutomationCampaigns(automationId)
  
  // Salvar no cache (5 minutos)
  serverCache.set(cacheKey, data, 300)
  
  return data
}
```

---

### **Op√ß√£o 3: Redis** üóÑÔ∏è **MAIS ROBUSTO**

**Descri√ß√£o:** Cache distribu√≠do usando Redis

**Vantagens:**
- ‚úÖ Persiste entre restarts
- ‚úÖ Compartilha entre m√∫ltiplas inst√¢ncias
- ‚úÖ TTL autom√°tico
- ‚úÖ Escal√°vel

**Desvantagens:**
- ‚ö†Ô∏è Requer infraestrutura Redis
- ‚ö†Ô∏è Mais complexo
- ‚ö†Ô∏è Custo adicional

**Setup:**

```bash
# Instalar depend√™ncias
npm install ioredis
```

**C√≥digo:**

```typescript
// src/lib/cache/redis-cache.ts
import Redis from 'ioredis'

const redis = new Redis(process.env.REDIS_URL)

export async function cacheGet<T>(key: string): Promise<T | null> {
  const data = await redis.get(key)
  return data ? JSON.parse(data) : null
}

export async function cacheSet(
  key: string,
  value: any,
  ttlSeconds: number = 300
): Promise<void> {
  await redis.set(key, JSON.stringify(value), 'EX', ttlSeconds)
}

export async function cacheDel(pattern: string): Promise<void> {
  const keys = await redis.keys(pattern)
  if (keys.length > 0) {
    await redis.del(...keys)
  }
}
```

**Uso:**

```typescript
const cacheKey = `automation:${automationId}:campaigns`

// Tentar cache
let data = await cacheGet<any[]>(cacheKey)

if (!data) {
  // Buscar da API
  data = await client.getAutomationCampaigns(automationId)
  
  // Salvar no cache
  await cacheSet(cacheKey, data, 300)
}
```

---

## üìä **Compara√ß√£o de Op√ß√µes**

| Op√ß√£o | Setup | Performance | Escalabilidade | Custo | Recomendado |
|-------|-------|-------------|----------------|-------|-------------|
| **unstable_cache** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Gr√°tis | ‚úÖ Sim |
| **Memory Cache** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Gr√°tis | ‚ö†Ô∏è Serverless n√£o |
| **Redis** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $$ | üîµ Produ√ß√£o |

---

## üéØ **Estrat√©gia de Cache Recomendada**

### **Camada 1: Query Cache (unstable_cache)**

```typescript
// Cache queries do banco
const automations = await getCachedAutomations(accountIds)
const campaigns = await getCachedCampaigns(automationIds)
```

**TTL:** 5 minutos  
**Invalida√ß√£o:** Ap√≥s sync

### **Camada 2: API Cache (unstable_cache)**

```typescript
// Cache chamadas ActiveCampaign
const apiCampaigns = await getCachedAutomationCampaigns(...)
const metrics = await getCachedCampaignMetrics(...)
```

**TTL:** 5 minutos  
**Invalida√ß√£o:** Ap√≥s sync

### **Camada 3: Computed Results (opcional)**

```typescript
// Cache resultado final processado
const results = await getCachedAutomationsWithMetrics(filters)
```

**TTL:** 2 minutos  
**Invalida√ß√£o:** Ao mudar filtros

---

## üìà **Impacto Esperado**

### **Cen√°rio Real (10 usu√°rios/hora):**

**SEM Cache:**
```
10 usu√°rios √ó 347 requests = 3,470 requests/hora
Tempo m√©dio: 40 segundos
ActiveCampaign API: Rate limit issues
```

**COM Cache:**
```
1¬∫ usu√°rio: 347 requests (preenche cache)
9 usu√°rios: ~30 requests (cache hits)
Total: ~377 requests/hora (89% redu√ß√£o!)
Tempo m√©dio: 3-5 segundos (87% mais r√°pido!)
```

---

## üõ†Ô∏è **Implementa√ß√£o Passo a Passo**

### **Fase 1: Setup Cache (30 min)**

```bash
# 1. Criar arquivo de cache
touch src/lib/cache/server-cache.ts

# 2. Implementar fun√ß√µes de cache (c√≥digo acima)

# 3. Adicionar types se necess√°rio
```

### **Fase 2: Integrar no Service (1 hora)**

```typescript
// Substituir chamadas diretas por vers√µes cachadas
- await client.getAutomationCampaigns(id)
+ await getCachedAutomationCampaigns(id, baseUrl, apiKey)

- await apiv1.getCampaignReportTotals(id, dates)
+ await getCachedCampaignMetrics(id, sdate, ldate, baseUrl, apiKey)
```

### **Fase 3: Invalida√ß√£o (30 min)**

```typescript
// Em sync-service.ts e actions/sync.ts
import { revalidateTag } from 'next/cache'

async syncAccount() {
  // ... sync logic
  
  // Invalidar caches
  revalidateTag('automations')
  revalidateTag('automation-campaigns')
  revalidateTag('campaign-metrics')
}
```

### **Fase 4: Teste (30 min)**

```bash
# 1. Primeira carga (deve ser lenta)
# 2. Segunda carga (deve ser r√°pida!)
# 3. Ap√≥s 5 min (deve renovar cache)
# 4. Ap√≥s sync (deve invalidar)
```

---

## üß™ **Valida√ß√£o**

### **M√©tricas de Sucesso:**

```
‚úÖ Primeira carga: 30-40s (aceit√°vel)
‚úÖ Cargas subsequentes: 2-5s (excelente!)
‚úÖ Cache hit rate: >80%
‚úÖ Requests √† API: -89%
```

### **Logs para Monitorar:**

```typescript
console.log(`‚úÖ Cache hit: automation:${id}`)
console.log(`üì° Cache miss: automation:${id}, fetching from API`)
console.log(`üîÑ Cache invalidated: automations`)
```

---

## ‚ö†Ô∏è **Considera√ß√µes**

### **Dados Desatualizados:**
- Cache de 5 minutos = dados podem ter at√© 5 min de atraso
- Solu√ß√£o: Invalidar cache ap√≥s sync

### **Mem√≥ria:**
- Cache em mem√≥ria cresce com uso
- Solu√ß√£o: Cleanup autom√°tico, TTL curto

### **Serverless (Vercel):**
- Memory cache n√£o funciona bem
- Solu√ß√£o: Usar `unstable_cache` (recomendado)

---

## üöÄ **Pr√≥ximos Passos**

1. ‚úÖ Implementar `unstable_cache` (Op√ß√£o 1)
2. ‚úÖ Integrar no `automation-metrics-service.ts`
3. ‚úÖ Adicionar invalida√ß√£o ap√≥s sync
4. ‚úÖ Testar performance
5. üîµ (Futuro) Migrar para Redis se escalar muito

---

**Quer que eu implemente a Op√ß√£o 1 (unstable_cache) agora?** üöÄ

